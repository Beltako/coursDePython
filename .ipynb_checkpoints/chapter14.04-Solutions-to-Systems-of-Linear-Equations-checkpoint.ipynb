{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "# 10.4 Solutions aux systèmes d'équations linéaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Considérons un système d'équations linéaires sous forme matricielle, $Ax=y$, où $A$ est une matrice $m \\times n$. Rappelons que cela signifie qu'il y a des équations $m$ et des inconnues $n$ dans notre système. Une **solution** à un système d’équations linéaires est un $x$ dans ${\\mathbb{R}}^n$ qui satisfait l’équation sous forme matricielle. En fonction des valeurs qui remplissent $A$ et $y$, il existe trois possibilités de solutions distinctes pour $x$. Soit il n’y a pas de solution pour $x$, soit il existe une solution unique pour $x$, soit il existe un nombre infini de solutions pour $x$. Ce fait n'est pas montré dans ce texte.\n",
    "\n",
    "**Cas 1 : Il n'y a pas de solution pour $x$.** Si ${rank}([A,y]) = {rank}(A) + 1$, alors $y$ est\n",
    "linéairement indépendant des colonnes de $A$. Par conséquent, $y$ n'est pas dans la plage de $A$ et, par définition, il ne peut pas y avoir de $x$ qui satisfasse l'équation. Ainsi, comparer Rank($[A,y]$) et Rank($A$) fournit un moyen simple de vérifier s’il n’existe pas de solutions à un système d’équations linéaires.\n",
    "\n",
    "**Cas 2 : Il existe une solution unique pour $x$.** Si ${rank}([A,y]) = {rank}(A)$, alors $y$ peut être écrit comme une combinaison linéaire des colonnes de $A$ et il existe au moins une solution pour l'équation matricielle. Pour qu’il n’y ait qu’une seule solution, ${rank}(A) = n$ doit également être vrai. En d’autres termes, le nombre d’équations doit être exactement égal au nombre d’inconnues. Pour comprendre pourquoi cette propriété aboutit à une solution unique, considérons les trois relations suivantes entre $m$ et $n: m < n, m = n$, et $m > n$.\n",
    "\n",
    "*Pour le cas où $m < n$, ${rank}(A) = n$ ne peut pas être vrai car cela signifie que nous avons une matrice \"grosse\" avec moins d'équations que d'inconnues. Nous n’avons donc pas besoin de considérer ce sous-cas.* Quand $m = n$ et ${rank}(A) = n$, alors $A$ est carré et inversible. Puisque l’inverse d’une matrice est unique, alors l’équation matricielle $Ax = y$ peut être résolue en multipliant chaque côté de l’équation, à gauche, par $A^{-1}$. Cela donne $A^{-1}Ax = A^{-1}y\\rightarrow Ix = A^{-1}y\\rightarrow x = A^{-1}y$, qui donne la solution unique à l'équation.\n",
    "*Si $m > n$, alors il y a plus d'équations que d'inconnues. Cependant, si ${rank}(A) = n$, alors il est possible de choisir des équations $n$ (c'est-à-dire des lignes de A) de telle sorte que si ces équations sont satisfaites, alors les équations $m - n$ restantes seront également satisfaites. En d’autres termes, ils sont redondants. Si les équations redondantes $m-n$ sont supprimées du système, alors le système résultant a une matrice $A$ qui est $n \\times n$ et inversible. Ces faits ne sont pas prouvés dans ce texte. Le nouveau système dispose alors d’une solution unique, valable pour l’ensemble du système.**Cas 3 : Il existe un nombre infini de solutions pour $x$.** Si ${rank}([A, y]) = {rank}(A)$, alors $y$ est dans la plage de $A$, et il existe au moins une solution pour l'équation matricielle. Cependant, si Rank($A$) $<$ $n$, alors il existe un nombre infini de solutions. La raison de ce fait est la suivante : bien que cela ne soit pas montré ici, si Rank($A$) $<$ $n$, alors il existe au moins un vecteur non nul, $n$, qui se trouve dans l'espace nul de $A$ (en fait, il y en a un nombre infini de vecteurs spatiaux nuls dans ces conditions.). Si $n$ est dans l'espace nul de $A$, alors $An = 0$ par définition. Soit maintenant $x^{{\\ast}}$ une solution de l'équation matricielle $Ax = y$ ; alors forcément, $Ax^{{\\ast}} = y$. Cependant, $Ax^{{\\ast}} + An = y$ ou $A(x^{{\\ast}} + n) = y$. $x^{{\\ast}} + n$ est donc aussi un\n",
    "solution pour $Ax = y$. En fait, puisque $A$ est une transformation linéaire, $x^{{\\ast}} + \\alpha n$ est une solution pour tout nombre réel, $\\alpha$ (vous devriez essayer de le montrer par vous-même). Puisqu’il existe un nombre infini de valeurs acceptables pour $\\alpha$, il existe un nombre infini de solutions pour l’équation matricielle.\n",
    "\n",
    "Dans le reste du chapitre, nous discuterons uniquement de la manière dont nous résolvons un système d’équations lorsqu’il a une solution unique. Nous discuterons de certaines des méthodes courantes que vous rencontrez souvent dans votre travail dans cette section. Et dans la section suivante, nous vous montrerons comment le résoudre en Python.\n",
    "\n",
    "Disons que nous avons n équations avec n variables, $Ax=y$, comme indiqué ci-dessous :\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} & ... & a_{1,n}\\\\\n",
    "a_{2,1} & a_{2,2} & ... & a_{2,n}\\\\\n",
    "... & ... & ... & ... \\\\\n",
    "a_{n,1} & a_{n,2} & ... & a_{n,n}\n",
    "\\end{bmatrix}\\left[\\begin{array}{c} x_1 \\\\x_2 \\\\ ... \\\\x_n \\end{array}\\right] =\n",
    "\\left[\\begin{array}{c} y_1 \\\\y_2 \\\\ ... \\\\y_n \\end{array}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "## Méthode d'élimination de Gauss\n",
    "\n",
    "La méthode **Gauss Elimination** est une procédure permettant de transformer la matrice $A$ en une forme **triangulaire supérieure** pour résoudre le système d'équations. Utilisons un système de 4 équations et 4 variables pour illustrer l'idée. L'élimination de Gauss transforme essentiellement le système d'équations en :\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} & a_{1,3} & a_{1,4}\\\\\n",
    "0 & a_{2,2}' & a_{2,3}' & a_{2,4}'\\\\\n",
    "0 & 0 & a_{3,3}' & a_{3,4}' \\\\\n",
    "0 & 0 & 0 & a_{4,4}'\n",
    "\\end{bmatrix}\\left[\\begin{array}{c} x_1 \\\\x_2 \\\\ x_3 \\\\x_4 \\end{array}\\right] =\n",
    "\\left[\\begin{array}{c} y_1 \\\\y_2' \\\\ y_3' \\\\y_4' \\end{array}\\right]$$\n",
    "\n",
    "En transformant la forme matricielle en ceci, nous pouvons voir les équations se transformer en :\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\begin{array}{}\n",
    " a_{1,1} x_1 &+& a_{1,2} x_2 & + & a_{1,3} x_{3} &+&a_{1,4} x_4 &=& y_1,\\\\\n",
    "& & a_{2,2}' x_{2} &+ & a_{2,3}' x_{3} &+& a_{2,4}' x_4 &=& y_{2}' \\\\\n",
    "&& & & a_{3,3}' x_{3} &+& a_{3,4}' x_4 &=& y_{3}',\\\\\n",
    "&& && && a_{4,4}' x_4 &=& y_{4}'.\n",
    "\\end{array}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Nous pouvons voir qu'en prenant cette forme, $x_4$ peut être facilement résolu en divisant les deux côtés $a_{4,4}'$, puis nous pouvons le remplacer dans la 3ème équation pour résoudre $x_3$. Avec $x_3$ et $x_4$, on peut les substituer à la 2ème équation pour résoudre $x_2$. Enfin, nous pouvons obtenir toutes les solutions pour $x$. Nous résolvons le système d'équations de bas en haut, c'est ce qu'on appelle **substitution arrière**. Notez que, si $A$ est une matrice triangulaire inférieure, nous résoudrons le système de haut en bas par **substitution directe**.\n",
    "\n",
    "Travaillons sur un exemple pour illustrer comment nous résolvons les équations en utilisant l'élimination de Gauss.\n",
    "\n",
    "**ESSAYEZ-LE !** Utilisez l'élimination de Gauss pour résoudre les équations suivantes.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "4x_1 + 3x_2 - 5x_3 &=& 2 \\\\\n",
    "-2x_1 - 4x_2 + 5x_3 &=& 5 \\\\\n",
    "8x_1 + 8x_2  &=& -3 \\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Étape 1 : Transformez ces équations sous forme matricielle $Ax=y$.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "4 & 3 & -5\\\\\n",
    "-2 & -4 & 5\\\\\n",
    "8 & 8 & 0\\\\\n",
    "\\end{bmatrix}\\left[\\begin{array}{c} x_1 \\\\x_2 \\\\x_3 \\end{array}\\right] =\n",
    "\\left[\\begin{array}{c} 2 \\\\5 \\\\-3\\end{array}\\right]$$\n",
    "\n",
    "Étape 2 : Obtenez la matrice augmentée [A, y]\n",
    "\n",
    "$$\n",
    "[A, y]  = \\begin{bmatrix}\n",
    "4 & 3 & -5 & 2\\\\\n",
    "-2 & -4 & 5 & 5\\\\\n",
    "8 & 8 & 0 & -3\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Étape 3 : Maintenant, nous commençons à éliminer les éléments de la matrice, nous le faisons en choisissant une **équation pivot**, qui est utilisée pour éliminer les éléments dans d'autres équations. Choisissons la première équation comme équation pivot et transformons le premier élément de la 2ème ligne à 0. Pour ce faire, nous pouvons multiplier -0,5 pour la 1ère ligne (équation pivot) et la soustraire de la 2ème ligne. Le multiplicateur est $m_{2,1}=-0.5$. Nous allons obtenir\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "4 & 3 & -5 & 2\\\\\n",
    "0 & -2.5 & 2.5 & 6\\\\\n",
    "8 & 8 & 0 & -3\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Étape 4 : Transformez le premier élément de la 3ème ligne à 0. Nous pouvons faire quelque chose de similaire, multiplier 2 par la 1ère ligne et le soustraire de la 3ème ligne. Le multiplicateur est $m_{3,1}=2$. Nous allons obtenir\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "4 & 3 & -5 & 2\\\\\n",
    "0 & -2.5 & 2.5 & 6\\\\\n",
    "0 & 2 & 10 & -7\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Étape 5 : Tournez le 2ème élément de la 3ème rangée à 0. Nous pouvons multiplier -4/5 pour la 2ème ligne et ajouter le soustraire de la 3ème ligne. Le multiplicateur est $m_{3,2}=-0.8$. Nous allons obtenir\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "4 & 3 & -5 & 2\\\\\n",
    "0 & -2.5 & 2.5 & 6\\\\\n",
    "0 & 0 & 12 & -2.2\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Étape 6 : Par conséquent, nous pouvons obtenir $x_3=-2.2/12=-0.183$.\n",
    "\n",
    "Étape 7 : Insérez $x_3$ dans la 2ème équation, nous obtenons $x_2=-2.583$\n",
    "\n",
    "Étape 8 : Insérez $x_2$ et $x_3$ dans la première équation, nous avons $x_1=2.208$.\n",
    "\n",
    "**Remarque !** Parfois, le premier élément de la 1ère ligne est 0, il suffit de changer la première ligne avec une première ligne d'élément non nulle, vous pourrez alors suivre la même procédure que ci-dessus.\n",
    "\n",
    "Nous utilisons ici la méthode d'élimination de Gauss \"pivotante\", mais vous devez savoir qu'il existe également une méthode d'élimination de Gauss \"naïve\" avec l'hypothèse que les valeurs pivots ne seront jamais nulles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "## Méthode d'élimination de Gauss-Jordan\n",
    "\n",
    "L'élimination de Gauss-Jordan résout les systèmes d'équations en utilisant une procédure pour transformer $A$ en une forme diagonale, de telle sorte que la forme matricielle des équations devienne\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0\\\\\n",
    "0 & 1 & 0 & 0\\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{bmatrix}\\left[\\begin{array}{c} x_1 \\\\x_2 \\\\ x_3 \\\\x_4 \\end{array}\\right] =\n",
    "\\left[\\begin{array}{c} y_1' \\\\y_2' \\\\ y_3' \\\\y_4' \\end{array}\\right]$$\n",
    "\n",
    "Essentiellement, les équations deviennent :\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\begin{array}{}\n",
    "x_1 &+& 0 & + & 0 &+&0 &=& y_1',\\\\\n",
    "0 &+& x_2 & + & 0 &+&0 &=& y_2' \\\\\n",
    "0 &+& 0 & + & x_3 &+&0 &=& y_3',\\\\\n",
    "0 &+& 0 & + & 0 &+&x_4 &=& y_4'.\n",
    "\\end{array}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Voyons toujours comment procéder en utilisant l'exemple ci-dessus.\n",
    "\n",
    "**ESSAYEZ-LE !** Utilisez l'élimination de Gauss-Jordan pour résoudre les équations suivantes.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "4x_1 + 3x_2 - 5x_3 &=& 2 \\\\\n",
    "-2x_1 - 4x_2 + 5x_3 &=& 5 \\\\\n",
    "8x_1 + 8x_2  &=& -3 \\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Étape 1 : Obtenez la matrice augmentée [A, y]\n",
    "\n",
    "$$\n",
    "[A, y]  = \\begin{bmatrix}\n",
    "4 & 3 & -5 & 2\\\\\n",
    "-2 & -4 & 5 & 5\\\\\n",
    "8 & 8 & 0 & -3\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Étape 2 : Mettez le premier élément de la 1ère ligne à 1, divisez 4 par ligne :\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 3/4 & -5/4 & 1/2\\\\\n",
    "-2 & -4 & 5 & 5\\\\\n",
    "8 & 8 & 0 & -3\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Étape 3 : Éliminez le premier élément des 2ème et 3ème rangées, multipliez -2 et 8 par la 1ère rangée et soustrayez-le des 2ème et 3ème rangées.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 3/4 & -5/4 & 1/2\\\\\n",
    "0 & -5/2 & 5/2 & 6\\\\\n",
    "0 & 2 & 10 & -7\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Étape 4 : Normalisez le 2ème élément de la 2ème rangée à 1, on divise -5/2 pour y parvenir.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 3/4 & -5/4 & 1/2\\\\\n",
    "0 & 1 & -1 & -12/5\\\\\n",
    "0 & 2 & 10 & -7\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Étape 5 : Eliminez le 2ème élément de la 3ème ligne, on multiplie 2 à la 2ème ligne et on le soustrait de la 3ème ligne.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 3/4 & -5/4 & 1/2\\\\\n",
    "0 & 1 & -1 & -12/5\\\\\n",
    "0 & 0 & 12 & -11/5\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Étape 6 : Normalisez la dernière ligne en divisant par 8.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 3/4 & -5/4 & 1/2\\\\\n",
    "0 & 1 & -1 & -12/5\\\\\n",
    "0 & 0 & 1 & -11/60\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Étape 7 : Éliminez le 3ème élément de la 2ème ligne en multipliant -1 par la 3ème ligne et soustrayez-le de la 2ème ligne.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 3/4 & -5/4 & 1/2\\\\\n",
    "0 & 1 & 0 & -155/60\\\\\n",
    "0 & 0 & 1 & -11/60\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Étape 8 : Éliminez le 3ème élément de la 1ère ligne en multipliant -5/4 par la 3ème ligne et soustrayez-le de la 1ère ligne.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 3/4 & 0 & 13/48\\\\\n",
    "0 & 1 & 0 & -2.583\\\\\n",
    "0 & 0 & 1 & -0.183\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Étape 9 : Éliminez le 2ème élément de la 1ère rangée en multipliant 3/4 par la 2ème rangée et soustrayez-le de la 1ère rangée.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 2.208\\\\\n",
    "0 & 1 & 0 & -2.583\\\\\n",
    "0 & 0 & 1 & -0.183\\\\\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "## Méthode de décomposition LU\n",
    "\n",
    "Nous voyons les deux méthodes ci-dessus qui impliquent de changer à la fois $A$ et $y$ en même temps lorsque nous essayons de transformer A en une forme de matrice triangulaire ou diagonale supérieure. Cela implique de nombreuses opérations. Mais parfois, nous pouvons avoir le même ensemble d’équations mais différents ensembles de $y$ pour différentes expériences. C'est en fait assez courant dans le monde réel, que nous ayons différentes observations expérimentales $y_a, y_b, y_c, ...$. Par conséquent, nous devons résoudre $Ax=y_a$, $Ax=y_b$, ... plusieurs fois, car à chaque fois $[A, y]$ changera. C'est vraiment inefficace, existe-t-il une méthode permettant de changer uniquement le côté gauche de $A$ mais pas la main droite de $y$ ? La méthode de décomposition LU est l'une des solutions consistant à changer uniquement la matrice $A$ au lieu de $y$. Il présente les avantages de résoudre les systèmes qui ont les mêmes matrices de coefficients $A$ mais des vecteurs constants différents $y$.\n",
    "\n",
    "La méthode de décomposition LU vise à transformer $A$ en une multiplication de deux matrices $L$ et $U$, où $L$ est une matrice triangulaire inférieure tandis que $U$ est une matrice triangulaire supérieure. Avec cette décomposition, nous convertissons le système d’équations sous la forme suivante :\n",
    "\n",
    "$$LUx=y\\rightarrow\n",
    "\\begin{bmatrix}\n",
    "l_{1,1} & 0 & 0 & 0\\\\\n",
    "l_{2,1} & l_{2,2} & 0 & 0\\\\\n",
    "l_{3,1} & l_{3,2} & l_{3,3} & 0 \\\\\n",
    "l_{4,1} & l_{4,2} & l_{4,3} & l_{4,4}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "u_{1,1} & u_{1,2} & u_{1,3} & u_{1,4}\\\\\n",
    "0 & u_{2,2} & u_{2,3} & u_{2,4}\\\\\n",
    "0 & 0 & u_{3,3} & u_{3,4} \\\\\n",
    "0 & 0 & 0 & u_{4,4}\n",
    "\\end{bmatrix}\\left[\\begin{array}{c} x_1 \\\\x_2 \\\\ x_3 \\\\x_4 \\end{array}\\right] =\n",
    "\\left[\\begin{array}{c} y_1 \\\\y_2 \\\\ y_3 \\\\y_4 \\end{array}\\right]$$\n",
    "\n",
    "Si nous définissons $Ux=M$, alors les équations ci-dessus deviennent :\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "l_{1,1} & 0 & 0 & 0\\\\\n",
    "l_{2,1} & l_{2,2} & 0 & 0\\\\\n",
    "l_{3,1} & l_{3,2} & l_{3,3} & 0 \\\\\n",
    "l_{4,1} & l_{4,2} & l_{4,3} & l_{4,4}\n",
    "\\end{bmatrix}M =\n",
    "\\left[\\begin{array}{c} y_1 \\\\y_2 \\\\ y_3 \\\\y_4 \\end{array}\\right]$$\n",
    "\n",
    "Nous pouvons facilement résoudre le problème ci-dessus par substitution directe (à l’opposé de la substitution arrière comme nous l’avons vu dans la méthode d’élimination de Gauss). Après avoir résolu M, nous pouvons facilement résoudre le reste du problème en utilisant la substitution vers l’arrière :\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "u_{1,1} & u_{1,2} & u_{1,3} & u_{1,4}\\\\\n",
    "0 & u_{2,2} & u_{2,3} & u_{2,4}\\\\\n",
    "0 & 0 & u_{3,3} & u_{3,4} \\\\\n",
    "0 & 0 & 0 & u_{4,4}\n",
    "\\end{bmatrix}\\left[\\begin{array}{c} x_1 \\\\x_2 \\\\ x_3 \\\\x_4 \\end{array}\\right] =\n",
    "\\left[\\begin{array}{c} m_1 \\\\m_2 \\\\ m_3 \\\\m_4 \\end{array}\\right]$$\n",
    "\n",
    "Mais comment calculer et obtenir les matrices $L$ et $U$ ? Il existe différentes façons d'obtenir la décomposition LU, regardons simplement une méthode en utilisant la méthode d'élimination de Gauss. D’après ce qui précède, nous savons que nous obtenons une matrice triangulaire supérieure après avoir effectué l’élimination de Gauss. Mais en même temps, nous obtenons également la matrice triangulaire inférieure, c'est juste que nous ne l'écrivons jamais explicitement. Lors de la procédure d'élimination de Gauss, la matrice $A$ se transforme en fait en multiplication de deux matrices comme indiqué ci-dessous. Avec la forme triangulaire supérieure droite, c'est celle que nous obtenons auparavant, mais la matrice triangulaire inférieure a la diagonale 1, et les multiplicateurs qui multiplient l'équation pivot pour éliminer les éléments pendant la procédure comme les éléments situés en dessous de la diagonale.\n",
    "\n",
    "$$A=\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0\\\\\n",
    "m_{2,1} & 1 & 0 & 0\\\\\n",
    "m_{3,1} & m_{3,2} & 1 & 0 \\\\\n",
    "m_{4,1} & m_{4,2} & m_{4,3} & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "u_{1,1} & u_{1,2} & u_{1,3} & u_{1,4}\\\\\n",
    "0 & u_{2,2} & u_{2,3} & u_{2,4}\\\\\n",
    "0 & 0 & u_{3,3} & u_{3,4} \\\\\n",
    "0 & 0 & 0 & u_{4,4}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Nous pouvons voir que nous pouvons obtenir à la fois $L$ et $U$ en même temps lorsque nous effectuons l'élimination de Gauss. Voyons l'exemple ci-dessus, où $U$ est celui que nous avons utilisé auparavant pour résoudre les équations, et $L$ est composé des multiplicateurs (vous pouvez consulter les exemples dans la section Élimination de Gauss).\n",
    "\n",
    "$$\n",
    "L = \\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "-0.5 & 1 & 0 \\\\\n",
    "2 & -0.8 & 1 \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$\n",
    "U = \\begin{bmatrix}\n",
    "4 & 3 & -5 \\\\\n",
    "0 & -2.5 & 2.5 \\\\\n",
    "0 & 0 & 60 \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "**ESSAYEZ-LE !** Vérifiez que les matrices $L$ et $U$ ci-dessus sont la décomposition LU de la matrice $A$. Il faudrait voir ça $A=LU$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LU= [[ 4.  3. -5.]\n",
      " [-2. -4.  5.]\n",
      " [ 8.  8.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "u = np.array([[4, 3, -5], \n",
    "              [0, -2.5, 2.5], \n",
    "              [0, 0, 12]])\n",
    "l = np.array([[1, 0, 0], \n",
    "              [-0.5, 1, 0], \n",
    "              [2, -0.8, 1]])\n",
    "\n",
    "print('LU=', np.dot(l, u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "## Méthodes itératives - Méthode Gauss-Seidel\n",
    "\n",
    "Les méthodes ci-dessus que nous avons présentées sont toutes des méthodes directes, dans lesquelles nous calculons la solution avec un nombre fini d'opérations. Dans cette section, nous présenterons une classe différente de méthodes, les **méthodes itératives** ou **méthodes indirectes**. Cela commence par une première estimation de la solution, puis améliore la solution à plusieurs reprises jusqu'à ce que le changement de solution soit inférieur à un seuil. Afin d’utiliser ce processus itératif, nous devons d’abord écrire la forme explicite d’un système d’équations. Si nous avons un système d'équations linéaires :\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} & ... & a_{1,n}\\\\\n",
    "a_{2,1} & a_{2,2} & ... & a_{2,n}\\\\\n",
    "... & ... & ... & ... \\\\\n",
    "a_{m,1} & a_{m,2} & ... & a_{m,n}\n",
    "\\end{bmatrix}\\left[\\begin{array}{c} x_1 \\\\x_2 \\\\ ... \\\\x_n \\end{array}\\right] =\n",
    "\\left[\\begin{array}{c} y_1 \\\\y_2 \\\\ ... \\\\y_m \\end{array}\\right]$$\n",
    "nous pouvons écrire sa forme explicite comme :\n",
    "\n",
    "$$\n",
    "x_i = \\frac{1}{a_{i,i}}\\Big[y_i - \\sum_{j=1, j \\ne i}^{j=n}{a_{i,j}x_j} \\Big]\n",
    "$$\n",
    "\n",
    "C'est la base des méthodes itératives, nous pouvons supposer des valeurs initiales pour tous les $x$ et les utiliser comme $x^{(0)}$. Dans la première itération, nous pouvons remplacer $x^{(0)}$ dans le côté droit de l'équation explicite ci-dessus et obtenir la solution de première itération $x^{(1)}$. Ainsi, nous pouvons remplacer $x^{(1)}$ dans l’équation et obtenir un substitut $x^{(2)}$. Les itérations se poursuivent jusqu'à ce que la différence entre $x^{(k)}$ et $x^{(k-1)}$ soit inférieure à une valeur prédéfinie.\n",
    "\n",
    "Pour que les méthodes itératives fonctionnent, nous avons besoin de conditions spécifiques pour que la solution converge. Une condition suffisante mais non nécessaire de la convergence est que la matrice des coefficients $a$ soit une **dominante diagonalement**. Cela signifie que dans chaque ligne de la matrice de coefficients $a$, la valeur absolue de l'élément diagonal est supérieure à la somme des valeurs absolues des éléments hors diagonale. Si la matrice des coefficients satisfait à la condition, l’itération convergera vers la solution. La solution pourrait encore converger même si cette condition n’est pas satisfaite.\n",
    "\n",
    "### Méthode Gauss-Seidel\n",
    "La **Méthode Gauss-Seidel** est une méthode itérative spécifique, qui utilise toujours la dernière valeur estimée pour chaque élément dans $x$. Par exemple, nous supposons d’abord les valeurs initiales de $x_2, x_3, \\cdots, x_n$ (sauf pour $x_1$), puis nous pouvons calculer $x_1$. En utilisant le $x_1$ calculé et le reste du $x$ (sauf $x_2$), nous pouvons calculer $x_2$. On peut continuer de la même manière et calculer tous les éléments dans $x$. Ceci conclura la première itération. Nous pouvons voir que la partie unique de la méthode Gauss-Seidel est que nous utilisons toujours la dernière valeur pour calculer la valeur suivante dans $x$. On peut alors continuer les itérations jusqu'à ce que la valeur converge. Utilisons cette méthode pour résoudre le même problème que nous venons de résoudre ci-dessus.\n",
    "\n",
    "**EXEMPLE :** Résolvez le système d'équations linéaires suivant en utilisant la méthode de Gauss-Seidel, utilisez un seuil prédéfini $\\epsilon = 0.01$. N'oubliez pas de vérifier si la condition de convergence est satisfaite ou non.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "8x_1 + 3x_2 - 3x_3 &=& 14 \\\\\n",
    "-2x_1 - 8x_2 + 5x_3 &=& 5 \\\\\n",
    "3x_1 + 5x_2 + 10x_3 & =& -8 \\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Vérifions d’abord si la matrice des coefficients est diagonalement dominante ou non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix is diagonally dominant\n"
     ]
    }
   ],
   "source": [
    "a = [[8, 3, -3], [-2, -8, 5], [3, 5, 10]]\n",
    "\n",
    "# Find diagonal coefficients\n",
    "diag = np.diag(np.abs(a)) \n",
    "\n",
    "# Find row sum without diagonal\n",
    "off_diag = np.sum(np.abs(a), axis=1) - diag \n",
    "\n",
    "if np.all(diag > off_diag):\n",
    "    print('matrix is diagonally dominant')\n",
    "else:\n",
    "    print('NOT diagonally dominant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Puisqu’il est garanti de converger, nous pouvons utiliser la méthode de Gauss-Seidel pour le résoudre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration results\n",
      " k,    x1,    x2,    x3 \n",
      "1, 1.7500, -1.0625, 1.5875\n",
      "2, 2.7437, -0.3188, 2.9275\n",
      "3, 2.9673, 0.4629, 3.8433\n",
      "4, 3.0177, 1.0226, 4.4332\n",
      "5, 3.0290, 1.3885, 4.8059\n",
      "6, 3.0315, 1.6208, 5.0397\n",
      "7, 3.0321, 1.7668, 5.1861\n",
      "8, 3.0322, 1.8582, 5.2776\n",
      "9, 3.0322, 1.9154, 5.3348\n",
      "10, 3.0323, 1.9512, 5.3705\n",
      "11, 3.0323, 1.9735, 5.3929\n",
      "12, 3.0323, 1.9875, 5.4068\n",
      "13, 3.0323, 1.9962, 5.4156\n",
      "14, 3.0323, 2.0017, 5.4210\n",
      "Converged!\n"
     ]
    }
   ],
   "source": [
    "x1 = 0\n",
    "x2 = 0\n",
    "x3 = 0\n",
    "epsilon = 0.01\n",
    "converged = False\n",
    "\n",
    "x_old = np.array([x1, x2, x3])\n",
    "\n",
    "print('Iteration results')\n",
    "print(' k,    x1,    x2,    x3 ')\n",
    "for k in range(1, 50):\n",
    "    x1 = (14-3*x2+3*x3)/8\n",
    "    x2 = (5+2*x1-5*x3)/(-8)\n",
    "    x3 = (-8-3*x1-5*x2)/(-5)\n",
    "    x = np.array([x1, x2, x3])\n",
    "    # check if it is smaller than threshold\n",
    "    dx = np.sqrt(np.dot(x-x_old, x-x_old))\n",
    "    \n",
    "    print(\"%d, %.4f, %.4f, %.4f\"%(k, x1, x2, x3))\n",
    "    if dx < epsilon:\n",
    "        converged = True\n",
    "        print('Converged!')\n",
    "        break\n",
    "        \n",
    "    # assign the latest x value to the old value\n",
    "    x_old = x\n",
    "\n",
    "if not converged:\n",
    "    print('Not converge, increase the # of iterations')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
