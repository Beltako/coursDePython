{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"images/book_cover.jpg\" width=\"120\">\n",
    "\n",
    "*Ce cahier contient un extrait de [Programmation Python et méthodes numériques - Un guide pour les ingénieurs et les scientifiques](https://pythonnumericalmethods.berkeley.edu/notebooks/Index.html), le contenu est également disponible sur [Berkeley Python Numerical Methods](https://pythonnumericalmethods.berkeley.edu/notebooks/Index.html).*\n",
    "\n",
    "*Les droits d'auteur du livre appartiennent à Elsevier. Nous avons également ce livre interactif en ligne pour une meilleure expérience d'apprentissage. Le code est publié sous la [licence MIT](https://opensource.org/licenses/MIT). Si vous trouvez ce contenu utile, pensez à soutenir le travail sur [Elsevier](https://www.elsevier.com/books/python-programming-and-numerical-methods/kong/978-0-12-819549-9) ou [Amazon](https://www.amazon.com/Python-Programming-Numerical-Methods-Scientists/dp/0128195495/ref=sr_1_1?dchild=1&keywords=Python+Programming+and+Numerical+Methods+-+A+Guide+for+Engineers+and+Scientists&qid=1604761352&sr=8-1) !*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<!--NAVIGATION-->\n",
    "< [16.5 Least Square Regression for Nonlinear Functions](chapter16.05-Least-Square-Regression-for-Nonlinear-Functions.ipynb)  | [Contents](Index.ipynb) | [CHAPTER 17. Interpolation](chapter17.00-Interpolation.ipynb) >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "# Résumé\n",
    "\n",
    "\n",
    "1. Les modèles mathématiques sont utilisés pour comprendre, prédire et contrôler les systèmes d’ingénierie. Ces modèles sont constitués de paramètres qui régissent le comportement du modèle.\n",
    "2. Étant donné un ensemble de données expérimentales, la régression des moindres carrés est une méthode permettant de trouver un ensemble de paramètres de modèle qui correspondent bien aux données. Autrement dit, il minimise l'erreur quadratique entre le modèle, ou la fonction d'estimation, et les points de données.\n",
    "3. Dans la régression linéaire des moindres carrés, la fonction d'estimation doit être une combinaison linéaire de fonctions de base linéairement indépendantes.\n",
    "4. L'ensemble de paramètres ${\\beta}$ peut être déterminé par l'équation des moindres carrés ${\\beta} = (A^T A)^{-1} A^T Y$, où la $j$-ème colonne de $A$ est la $j$-ème fonction de base évaluée à chaque point de données $X$.\n",
    "5. Pour estimer une fonction non linéaire, nous pouvons la transformer en fonction d'estimation linéaire ou utiliser directement la régression des moindres carrés pour résoudre la fonction non linéaire en utilisant *curve_fit* de scipy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "# Problèmes\n",
    "\n",
    "1. Répétez la dérivation du calcul multivariable de la formule de régression des moindres carrés pour une fonction d'estimation $\\hat{y}(x) = ax^2 + bx + c$ où $a, b$ et $c$ sont les paramètres.\n",
    "\n",
    "2. Écrivez une fonction *my_ls_params(f, x, y)*, où *x* et *y* sont des tableaux de même taille contenant des données expérimentales, et *f* est une liste avec chaque élément un objet fonction à un vecteur de base de la fonction d'estimation. L'argument de sortie, *beta*, doit être un tableau des paramètres de la régression des moindres carrés pour *x*, *y* et *f*.\n",
    "\n",
    "3. Écrivez une fonction *my_func_fit (x,y)*, où *x* et *y* sont des vecteurs colonnes de même taille contenant des données expérimentales, et la fonction renvoie < *>alpha*et*beta*sont les paramètres de la fonction d'estimation $\\hat{y}(x) = {\\alpha} x^{{\\beta}}$.\n",
    "\n",
    "4. Étant donné quatre points de données $(x_i, y_i)$ et les paramètres d'un polynôme cubique $\\hat{y}(x) = ax^3 + bx^2 + cx + d$, quelle sera l'erreur totale associée à la fonction d'estimation $\\hat{y}(x)$ ? Où pouvons-nous placer un autre point de données*(x,y)*de telle sorte qu'aucune erreur supplémentaire ne soit induite pour la fonction d'estimation ?\n",
    "\n",
    "5. Écrivez une fonction*my_lin_regression(f, x, y)*, où*f*est une liste contenant des objets de fonction pour baser les fonctions, et*x*et*y*sont des tableaux contenant des données bruitées. Supposons que*x*et*y*aient la même taille.\n",
    "\n",
    " Supposons qu'une fonction d'estimation pour les données contenues dans*x*et*y*soit définie comme $\\hat{y}(x) = {\\beta}(1) \\cdot f_{1}(x) + {\\beta}(2) \\cdot f_{2}(x) + \\cdots + {\\beta}(n) \\cdot f_{n}(x)$, où*n*est la longueur de*f*. Votre fonction doit calculer*bêta*selon la formule de régression des moindres carrés.\n",
    "\n",
    " Cas de test : notez que votre solution peut varier légèrement en fonction des nombres aléatoires générés.\n",
    " \n",
    "```python\n",
    "x = np.linspace(0, 2*np.pi, 1000)\n",
    "y = 3*np.sin(x) - 2*np.cos(x) + np.random.random(len(x))\n",
    "f = [np.sin, np.cos]\n",
    "bêta = my_lin_regression(f, x, y)\n",
    "\n",
    "plt.figure (taille de la figure = (10,8))\n",
    "plt.plot(x,y,'b.', étiquette = 'données')\n",
    "plt.plot(x, beta[0]*f[0](x)+beta[1]*f[1](x)+beta[2], 'r', label='régression' )\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Exemple de régression des moindres carrés')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "<img src=\"./images/16.06.01-problem_5_example.jpg\" alt=\"problem 5 example\" title=\"Results from problem 5\" width=\"500\"/>\n",
    "\n",
    "6. Écrivez une fonction*my<_>exp<_>regression (x,y)*, où*x*et*y*sont des tableaux de même taille.\n",
    "\n",
    " Supposons qu'une fonction d'estimation pour les données contenues dans*x*et*y*soit définie comme $\\hat{y}(x) = {\\alpha} e^{{\\beta} x}$. Votre fonction doit calculer ${\\alpha}$ et ${\\beta}$ comme solution à la formule de régression des moindres carrés.\n",
    "\n",
    " Cas de test : notez que votre solution peut différer légèrement du scénario de test en fonction des nombres aléatoires générés.\n",
    " \n",
    "```python\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = 2*np.exp(-0.5*x) + 0.25*np.random.random(len(x))\n",
    "\n",
    "alpha, bêta = ma<_>exp<_>régression(x, y)\n",
    "\n",
    "plt.figure (taille de la figure = (10,8))\n",
    "plt.plot(x,y,'b.', étiquette = 'données')\n",
    "plt.plot(x, alpha*np.exp(beta<*>x), 'r', label='regression')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Régression des moindres carrés sur le modèle exponentiel')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "<img src=\"./images/16.06.02-problem_6_example.jpg\" alt=\"problem 5 example\" title=\"Results from problem 6\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<!--NAVIGATION-->\n",
    "< [16.5 Least Square Regression for Nonlinear Functions](chapter16.05-Least-Square-Regression-for-Nonlinear-Functions.ipynb)  | [Contents](Index.ipynb) | [CHAPTER 17. Interpolation](chapter17.00-Interpolation.ipynb) >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
